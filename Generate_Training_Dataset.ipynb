{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicoStaedeli/ML-Eurosat/blob/main/Generate_Training_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVUr5xZCGTE8"
      },
      "source": [
        "# **Exploring and Preparing the EuroSAT Dataset for Model Training**  \n",
        "\n",
        "In this notebook, we analyze images from the **EuroSAT dataset**, which is derived from **Sentinel-2 satellite imagery**. Additionally, we examine the images from the **evaluation dataset**, stored as `.npy` files containing **12 spectral bands**.  \n",
        "\n",
        "The primary objective is to process and standardize these images into a consistent shape, ensuring they are suitable for model training.\n",
        "\n",
        "## Creation of Training Dataset\n",
        "The dataset for the training is created from 12 of the 13 bands of the original image. The band 10 of the orignial image was removed due the assumption that this band was not used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBeKoVksD-hh",
        "outputId": "f1005128-a90f-4a90-cdce-470e23a571a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XWUIXomEO89",
        "outputId": "6fae704a-9835-431e-f2f8-d6633f0c09a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR64_pmhEnv-"
      },
      "source": [
        "Load dataset into instance for faster inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvgNXr4XKloe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOJkddONEnG9"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/HSG/ML/Project/Datasets/EuroSATallBands.zip /content/\n",
        "\n",
        "!unzip /content/EuroSATallBands.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeQhxjOXEr0F"
      },
      "outputs": [],
      "source": [
        "path_dataset_train_tif = '/content/dataset/ds/images/remote_sensing/otherDatasets/sentinel_2/tif'\n",
        "path_dataset_test_npy = '/content/drive/MyDrive/HSG/ML/Project/Datasets/Challenge Testdata/testset/testset'\n",
        "path_dataset_processed_tif_to_npy = '/content/processed_dataset'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTv_AkvIMANu"
      },
      "source": [
        "## Convert\n",
        "\n",
        "\n",
        "*   Convert Images from GeoTiff format to Numpy image\n",
        "*   remove band 10\n",
        "*   place band 13 which is Band 8A at 9th position\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1PuyNDHKjmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "import os\n",
        "\n",
        "# Define input and output paths\n",
        "input_dir = path_dataset_train_tif\n",
        "output_dir = path_dataset_processed_tif_to_npy\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def convert_tif_to_npy(tif_path, npy_output_path):\n",
        "    # Load the .tif image\n",
        "    tif_image = tiff.imread(tif_path)\n",
        "\n",
        "    # Check that the image has at least 13 bands (original image should)\n",
        "    if tif_image.shape[-1] >= 13:\n",
        "        # Remove Band 10 (index 9)\n",
        "        tif_image = np.delete(tif_image, 9, axis=-1)\n",
        "\n",
        "        # Extract Band 13 (original index 12, but after deletion it becomes 11)\n",
        "        band_13 = tif_image[..., 11]\n",
        "\n",
        "        # Remove the current Band 13 (now at index 11 after deletion)\n",
        "        tif_image = np.delete(tif_image, 11, axis=-1)\n",
        "\n",
        "        # Insert Band 13 at position 8 (index 8)\n",
        "        tif_image = np.insert(tif_image, 8, band_13, axis=-1)\n",
        "    else:\n",
        "        raise ValueError(f\"Image at {tif_path} does not have at least 13 bands.\")\n",
        "\n",
        "    # Save the converted image as .npy\n",
        "    np.save(npy_output_path, tif_image)\n",
        "    print(f\"Saved converted image to {npy_output_path}\")\n",
        "\n",
        "def process_tif_folder(input_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate over each class directory\n",
        "    for class_folder in os.listdir(input_dir):\n",
        "        class_path = os.path.join(input_dir, class_folder)\n",
        "\n",
        "        # Ensure it's a directory (skip files)\n",
        "        if os.path.isdir(class_path):\n",
        "            # Process all .tif images inside this class folder\n",
        "            for filename in os.listdir(class_path):\n",
        "                if filename.endswith(\".tif\"):\n",
        "                    input_path = os.path.join(class_path, filename)\n",
        "\n",
        "                    # Flatten output - use class name + filename for uniqueness\n",
        "                    output_filename = f\"{filename.replace('.tif', '.npy')}\"\n",
        "                    output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "                    convert_tif_to_npy(input_path, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_tif_folder(input_dir, output_dir)"
      ],
      "metadata": {
        "id": "pINB22VS1Lg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiXOqy53JOCW",
        "outputId": "a7545c3a-9c94-453c-e954-b38e9c9afe6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of .npy files: 27000\n"
          ]
        }
      ],
      "source": [
        "# Get list of .npy files\n",
        "image_files = glob.glob(os.path.join(path_dataset_processed_tif_to_npy, \"*.npy\"))\n",
        "# Count .npy files\n",
        "file_count = len(image_files)\n",
        "\n",
        "print(f\"Number of .npy files: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBQbo2jAXAvx",
        "outputId": "8df5acb8-c972-4484-f4d5-867410f9a000"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset successfully copied to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "#store to drive for later inference\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "drive_dataset_path = \"/content/drive/MyDrive/HSG/ML/Project/Datasets/Eurosat_train_dataset/\"\n",
        "\n",
        "# Ensure the target directory exists\n",
        "shutil.os.makedirs(drive_dataset_path, exist_ok=True)\n",
        "\n",
        "# Copy the entire folder\n",
        "shutil.copytree(path_dataset_processed_tif_to_npy, drive_dataset_path, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Dataset successfully copied to Google Drive!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPkXI23wKcpJ",
        "outputId": "671433e3-75a3-4cac-e817-ccd1c7715e6a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of .npy files: 27000\n"
          ]
        }
      ],
      "source": [
        "# Get list of .npy files\n",
        "image_files = glob.glob(os.path.join(drive_dataset_path, \"*.npy\"))\n",
        "# Count .npy files\n",
        "file_count = len(image_files)\n",
        "\n",
        "print(f\"Number of .npy files: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the folder you want to zip\n",
        "path_dataset_processed_tif_to_npy = '/content/processed_dataset'\n",
        "\n",
        "# Output zip file path (without .zip extension)\n",
        "output_zip_path = '/content/EuroSAT_training_dataset_numpy'\n",
        "\n",
        "# Create the zip file\n",
        "shutil.make_archive(output_zip_path, 'zip', path_dataset_processed_tif_to_npy)\n",
        "\n",
        "print(f\"Folder zipped successfully at {output_zip_path}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViwwV7Ey-_43",
        "outputId": "be6d0541-85eb-44a9-af04-3b835f727d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder zipped successfully at /content/EuroSAT_training_dataset_numpy.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dataset_path_zip = '/content/drive/MyDrive/HSG/ML/Project/Datasets/'\n",
        "output_zip_path = '/content/EuroSAT_training_dataset_numpy.zip'\n",
        "\n",
        "shutil.copy(output_zip_path, drive_dataset_path_zip)\n",
        "\n",
        "print(f\"Zipped folder copied to: {drive_dataset_path_zip}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb_0h-zN_oeO",
        "outputId": "ae084606-02b9-4db9-c993-a81c6f4e5b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped folder copied to: /content/drive/MyDrive/HSG/ML/Project/Datasets/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1hsQI5_YYhaeWqJLV0HBK3TYRCXrKr15a",
      "authorship_tag": "ABX9TyPkDM0gQVEVNPh80p4CjRpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}